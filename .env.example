# Turbo Local Coder Agent Configuration
# Copy this file to .env and configure your settings

# LLM Endpoints
TURBO_HOST=https://ollama.com
OLLAMA_LOCAL=http://127.0.0.1:11434

# Model Configuration  
PLANNER_MODEL=gpt-oss:20b
CODER_MODEL=qwen2.5-coder:latest

# API Keys (if needed)
OLLAMA_API_KEY=

# Execution Settings
MAX_STEPS=25
REQUEST_TIMEOUT_S=120
DRY_RUN=0

# Security Settings
ALLOWED_FILE_EXTENSIONS=.py,.js,.ts,.md,.txt,.json,.yml,.yaml
BLOCKED_DIRECTORIES=/etc,/usr,/var,/boot
MAX_FILE_SIZE_MB=10

# Optional: Monitoring
LOG_LEVEL=INFO
METRICS_ENABLED=0